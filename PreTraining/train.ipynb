{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m to_categorical\n\u001b[0;32m     10\u001b[0m \u001b[39m# import train_test_split\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_selection\u001b[39;00m \u001b[39mimport\u001b[39;00m train_test_split\n\u001b[0;32m     13\u001b[0m \u001b[39m# import \u001b[39;00m\n\u001b[0;32m     15\u001b[0m gpus \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mlist_physical_devices(\u001b[39m'\u001b[39m\u001b[39mGPU\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'  # or any {'0', '1', '2'}\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow\n",
    "from keras.utils import to_categorical\n",
    "# import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# import \n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    for gpu in gpus:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read dataset:\n",
    "df = pd.read_csv('../Data/dataset/VETUSDT_labelled.csv')\n",
    "df.drop(['original_close', 'original_open', 'original_high', 'original_low', 'original_volume', 'event_time'], axis=1, inplace=True)\n",
    "\n",
    "df['balance'] = 100\n",
    "df['coin_amount'] = 0\n",
    "X = df.drop(['action'], axis=1)\n",
    "y = df['action']\n",
    "y = to_categorical(y, num_classes=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.00002\n",
    "input_shape = (100, 19)\n",
    "\n",
    "sequence_length = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create sequences as generator\n",
    "def create_sequences(df, sequence_length):\n",
    "    sequences = []\n",
    "    for x in range(sequence_length, len(df) - sequence_length):\n",
    "        sequences.append(df[x - sequence_length:x]) \n",
    "    return np.array(sequences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = tf.keras.Sequential()\n",
    "\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.add(layers.LSTM(200, input_shape=input_shape, return_sequences=True))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "    model.add(layers.LSTM(128, return_sequences=True))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "    model.add(layers.LSTM(64, return_sequences=True))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "    model.add(layers.LSTM(32))\n",
    "    model.add(layers.Dense(16, activation='linear'))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "    model.add(layers.Dense(3, activation='softmax'))\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['mae', 'accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unexpected result of `train_function` (Empty logs). Please use `Model.compile(..., run_eagerly=True)`, or `tf.config.run_functions_eagerly(True)` for more information of where went wrong, or file a issue/bug to `tf.keras`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 6\u001b[0m\n\u001b[0;32m      2\u001b[0m y_train \u001b[39m=\u001b[39m create_sequences(y, sequence_length)\n\u001b[0;32m      4\u001b[0m model \u001b[39m=\u001b[39m create_model()\n\u001b[1;32m----> 6\u001b[0m model\u001b[39m.\u001b[39;49mfit(X_train, y_train, batch_size\u001b[39m=\u001b[39;49m\u001b[39m64\u001b[39;49m, epochs\u001b[39m=\u001b[39;49m\u001b[39m1000\u001b[39;49m, verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\jonas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\jonas\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training.py:1576\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1574\u001b[0m logs \u001b[39m=\u001b[39m tf_utils\u001b[39m.\u001b[39msync_to_numpy_or_python_type(logs)\n\u001b[0;32m   1575\u001b[0m \u001b[39mif\u001b[39;00m logs \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1576\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1577\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mUnexpected result of `train_function` \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1578\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m(Empty logs). Please use \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1579\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m`Model.compile(..., run_eagerly=True)`, or \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1580\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m`tf.config.run_functions_eagerly(True)` for more \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1581\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39minformation of where went wrong, or file a \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1582\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39missue/bug to `tf.keras`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1583\u001b[0m     )\n\u001b[0;32m   1584\u001b[0m epoch_logs \u001b[39m=\u001b[39m copy\u001b[39m.\u001b[39mcopy(logs)\n\u001b[0;32m   1586\u001b[0m \u001b[39m# Run validation.\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: Unexpected result of `train_function` (Empty logs). Please use `Model.compile(..., run_eagerly=True)`, or `tf.config.run_functions_eagerly(True)` for more information of where went wrong, or file a issue/bug to `tf.keras`."
     ]
    }
   ],
   "source": [
    "X_train = create_sequences(X, sequence_length)\n",
    "y_train = create_sequences(y, sequence_length)\n",
    "\n",
    "model = create_model()\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=64, epochs=1000, verbose=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('pretrained_lstm_layers.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_4 (LSTM)               (None, 100, 200)          176000    \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 100, 200)          0         \n",
      "                                                                 \n",
      " lstm_5 (LSTM)               (None, 100, 128)          168448    \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 100, 128)          0         \n",
      "                                                                 \n",
      " lstm_6 (LSTM)               (None, 100, 64)           49408     \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 100, 64)           0         \n",
      "                                                                 \n",
      " lstm_7 (LSTM)               (None, 32)                12416     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 406,272\n",
      "Trainable params: 406,272\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model = tf.keras.models.load_model('pretrained_lstm_layers.h5')\n",
    "\n",
    "# remove last layer\n",
    "new_model = tf.keras.models.Sequential(base_model.layers[:-1])\n",
    "\n",
    "\n",
    "new_model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "683e9bbf599fde3b00e37a0db68ad40a268db525b46af3924c3427b16ddb8792"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
